{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Audio Diffusion Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch import Tensor\n",
    "from typing import Callable\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torchaudio as ta\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, reduce\n",
    "from IPython.display import Audio, Markdown\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from audio_diffusion_pytorch import KarrasSchedule\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "def display_audio(signal: torch.Tensor, sr: int):\n",
    "    display(Audio(signal.squeeze(0).cpu(), rate=sr))\n",
    "\n",
    "def display_md(text: str):\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sine-waves example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "The model we will be using is a 1-dimensional UNet, improved with attention layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: audio_diffusion_pytorch needs to be version 0.0.43\n",
    "from audio_diffusion_pytorch import AudioDiffusionModel, LogNormalDistribution\n",
    "\n",
    "model = AudioDiffusionModel(\n",
    "    in_channels=1,\n",
    "    channels=64,\n",
    "    patch_factor=16,\n",
    "    patch_blocks=1,\n",
    "    resnet_groups=8,\n",
    "    kernel_multiplier_downsample=2,\n",
    "    kernel_sizes_init=[1, 3, 7],\n",
    "    multipliers=[1, 2, 4, 4, 4],\n",
    "    factors=[4, 4, 2, 2],\n",
    "    num_blocks= [2, 2, 2, 2],\n",
    "    attentions= [False, False, False, True],\n",
    "    attention_heads=4,\n",
    "    attention_features=64,\n",
    "    attention_multiplier=2,\n",
    "    use_nearest_upsample=False,\n",
    "    use_skip_scale=True,\n",
    "    use_attention_bottleneck=True,\n",
    "    diffusion_sigma_distribution=LogNormalDistribution(mean=-3.0, std=1.0),\n",
    "    diffusion_sigma_data=0.2,\n",
    "    diffusion_dynamic_threshold=0.0,\n",
    ")\n",
    "\n",
    "model.to(\"cuda:0\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_samples: int, batch_size: int, sample_length: int, device: str, learning_rate: float):\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()), lr=learning_rate, betas=(0.9, 0.99))\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i in tqdm(range(num_samples)):\n",
    "            \n",
    "        # Generate input sine wave\n",
    "        period, shift = torch.rand(size=(2, batch_size,1,1))\n",
    "        x = torch.linspace(0, 1, sample_length)\n",
    "        x = torch.sin( 2*np.pi / period * (x + shift)).to(device)\n",
    "        \n",
    "        # Add noise to input (x + sigma * eps)\n",
    "        sigmas = model.diffusion.sigma_distribution(num_samples=batch_size, device=device)\n",
    "        x_noisy =  x + sigmas.view(-1,1,1) * torch.randn_like(x)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute denoised values\n",
    "        x_denoised = model.diffusion.denoise_fn(x_noisy, sigmas=sigmas)\n",
    "        \n",
    "        # Compute weighted loss, each entry weighted by sigma**2\n",
    "        losses = torch.nn.functional.mse_loss(x_denoised, x, reduction=\"none\")\n",
    "        losses = reduce(losses, \"b ... -> b\", \"mean\")\n",
    "        losses = losses * model.diffusion.loss_weight(sigmas)\n",
    "        loss = losses.mean()\n",
    "\n",
    "        # Compute the loss gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then start the training loop. We will use in total 256000 examples of sine-waves with random shift and period, with maximum period length equal to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "# Training loop\n",
    "train_model(\n",
    "    model, \n",
    "    num_samples=1000, \n",
    "    batch_size=256, \n",
    "    sample_length=4096,\n",
    "    device=device,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "# Show results\n",
    "display_md(\"**Training Complete!**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sampling\n",
    "For sampling, similarly to NCSN, we can use annealed langevin dynamics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_with_annealed_langevin(noise: Tensor, denoise_fn: Callable, sigmas: Tensor, T: int = 100, eps: float = 2e-5):    \n",
    "    # Create initial noise\n",
    "    sigma_L = sigmas[-1]\n",
    "    x = sigmas[0] * noise\n",
    "    \n",
    "    # For each noise level\n",
    "    for sigma_i in tqdm(sigmas):\n",
    "        alpha_i = eps*sigma_i**2/sigma_L**2\n",
    "        \n",
    "        # For each correction step\n",
    "        for t in range(T):\n",
    "            \n",
    "            # Compute score (slightly different formulation from NCSN)\n",
    "            score = (denoise_fn(x, sigma=sigma_i) - x) / sigma_i**2\n",
    "            \n",
    "            # Langevin Dynamics\n",
    "            x = x + 0.5 * alpha_i * score + torch.randn_like(x) * torch.sqrt(alpha_i) \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.random.manual_seed(1)\n",
    "\n",
    "# Set model in inference mode (no dropout, etc.)\n",
    "model.eval()\n",
    "\n",
    "# Starting noise (batch-size, num-sources, num-elements)\n",
    "noise = torch.randn((4, 1, 4096) , device=device) \n",
    "\n",
    "# Denoise-function (approximates grad-log-prob)\n",
    "gradlogp_fn = model.diffusion.denoise_fn\n",
    "\n",
    "# Solver timesteps distribution\n",
    "timesteps = KarrasSchedule(sigma_min=0.01, sigma_max=10.0, rho=5.0)(10, device) # < faster convergence\n",
    "\n",
    "# Sample from learned distribution\n",
    "y1, y2, y3, y4 = sample_with_annealed_langevin(noise, gradlogp_fn, timesteps[:-1])\n",
    "\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(y1.view(-1).cpu())\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(y2.view(-1).cpu())\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(y3.view(-1).cpu())\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(y4.view(-1).cpu())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
